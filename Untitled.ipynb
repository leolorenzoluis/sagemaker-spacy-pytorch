{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='local',\n",
    "                    train_volume_size=100,\n",
    "                    source_dir='.'\n",
    "#                     image_name='118104210923.dkr.ecr.us-east-1.amazonaws.com/spacy-pytorch-transformers:1.0.0-gpu-py3'\n",
    "#                     hyperparameters={\n",
    "#                         'epochs': 6,\n",
    "#                         'backend': 'gloo'\n",
    "#                     })\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmprnc594mq_algo-1-xd9ym_1 ... \n",
      "\u001b[1BAttaching to tmprnc594mq_algo-1-xd9ym_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:33:35,411 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:33:35,414 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:33:35,426 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:33:35,427 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:33:36,232 sagemaker-containers INFO     Module train does not provide a setup.py. \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:33:36,232 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:33:36,232 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:33:36,232 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m /usr/bin/python -m pip install . -r requirements.txt\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Collecting pandas==0.25.1 (from -r requirements.txt (line 1))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.5MB 4.7MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hRequirement already satisfied: wasabi==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.2.2)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Collecting gputil==1.4.0 (from -r requirements.txt (line 3))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Collecting scikit-learn>=0.20.0 (from -r requirements.txt (line 4))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.7MB 6.9MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting tqdm==4.36.1 (from -r requirements.txt (line 5))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 30.0MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting joblib==0.13.2 (from -r requirements.txt (line 6))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K    100% |████████████████████████████████| 286kB 40.1MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting spacy-pytorch-transformers[cuda100]==0.4.0 (from -r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/46/3271586944ee5e0bd493df03b1ad189eb9ccdad1d2476aeb843b0d2f1b47/spacy_pytorch_transformers-0.4.0-py3-none-any.whl (62kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 34.6MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting en_pytt_xlnetbasecased_lg from https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz#egg=en_pytt_xlnetbasecased_lg (from -r requirements.txt (line 8))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz (433.9MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (2019.2)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (2.8.0)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (1.16.4)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.1.0)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Collecting torchcontrib<0.1.0,>=0.0.2 (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Collecting ftfy<6.0.0,>=5.0.0 (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 29.1MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hRequirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.7)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.6)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: spacy<2.2.0,>=2.1.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.1.8)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Collecting pytorch-transformers<1.3.0,>=1.2.0 (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 40.9MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting cupy-cuda100>=5.0.0b4; extra == \"cuda100\" (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/40/e06241c414fbd1d9b0adb69a32f3759e40cfec92e76a07f27f186ab6a8e4/cupy_cuda100-7.0.0b4-cp36-cp36m-manylinux1_x86_64.whl (382.0MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting thinc-gpu-ops<0.1.0,>=0.0.1; extra == \"cuda100\" (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/ad/11ab80a24bcedd7dd0cfabaedba2ceaeca11f1aaeeff432a3d2e63ca7d02/thinc_gpu_ops-0.0.4.tar.gz (483kB)\n",
      "\u001b[K    100% |████████████████████████████████| 491kB 39.1MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.1->-r requirements.txt (line 1)) (1.12.0)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Collecting wcwidth (from ftfy<6.0.0,>=5.0.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0.8)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.22.0)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.0.2)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.0.2)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.0.1)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.2.4)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.9.6)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.9.209)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Collecting regex (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
      "\u001b[K    100% |████████████████████████████████| 655kB 29.4MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting sacremoses (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/04/b92425ca552116afdb7698fa3f00ca1c975cfd86a847cf132fd813c5d901/sacremoses-0.0.34.tar.gz (859kB)\n",
      "\u001b[K    100% |████████████████████████████████| 860kB 26.3MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting sentencepiece (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 25.6MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25hCollecting fastrlock>=0.3 (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/b5/93/a7efbd39eac46c137500b37570c31dedc2d31a8ff4949fcb90bda5bc5f16/fastrlock-0.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2019.6.16)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.8)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.25.3)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (3.0.4)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: botocore<1.13.0,>=1.12.209 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.12.209)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.2.1)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.9.4)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.209->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.15.2)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Building wheels for collected packages: gputil, en-pytt-xlnetbasecased-lg, train, torchcontrib, ftfy, thinc-gpu-ops, regex, sacremoses\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Running setup.py bdist_wheel for gputil ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Running setup.py bdist_wheel for en-pytt-xlnetbasecased-lg ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/30/9b/00/b570788126042185cd1f038f136e29f3a93a8dc824a35f6582\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Running setup.py bdist_wheel for train ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-1bib2yga/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Running setup.py bdist_wheel for torchcontrib ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Running setup.py bdist_wheel for ftfy ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Running setup.py bdist_wheel for thinc-gpu-ops ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/eb/ba/a3/9af9f326ed0d75a4540378af64a05a0e42be39d9b8513f3aea\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Running setup.py bdist_wheel for regex ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Running setup.py bdist_wheel for sacremoses ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/07/b9/5b/8bd674c23e962fbff34420a9fa7a2c374d591ecadd5bc37684\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Successfully built gputil en-pytt-xlnetbasecased-lg train torchcontrib ftfy thinc-gpu-ops regex sacremoses\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Installing collected packages: pandas, gputil, joblib, scikit-learn, tqdm, torchcontrib, wcwidth, ftfy, regex, sacremoses, sentencepiece, pytorch-transformers, fastrlock, cupy-cuda100, thinc-gpu-ops, spacy-pytorch-transformers, en-pytt-xlnetbasecased-lg, train\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Found existing installation: pandas 0.25.0\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     Uninstalling pandas-0.25.0:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m       Successfully uninstalled pandas-0.25.0\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m   Found existing installation: tqdm 4.33.0\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     Uninstalling tqdm-4.33.0:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m       Successfully uninstalled tqdm-4.33.0\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Successfully installed cupy-cuda100-7.0.0b4 en-pytt-xlnetbasecased-lg-2.1.1 fastrlock-0.4 ftfy-5.6 gputil-1.4.0 joblib-0.13.2 pandas-0.25.1 pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.34 scikit-learn-0.21.3 sentencepiece-0.1.83 spacy-pytorch-transformers-0.4.0 thinc-gpu-ops-0.0.4 torchcontrib-0.0.2 tqdm-4.36.1 train-1.0.0 wcwidth-0.1.7\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[33mYou are using pip version 18.1, however version 19.2.3 is available.\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:35:33,409 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:35:33,422 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"current_host\": \"algo-1-xd9ym\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m         \"algo-1-xd9ym\"\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"job_name\": \"sagemaker-pytorch-2019-09-28-01-32-35-616\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"master_hostname\": \"algo-1-xd9ym\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-118104210923/sagemaker-pytorch-2019-09-28-01-32-35-616/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m         \"current_host\": \"algo-1-xd9ym\",\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m             \"algo-1-xd9ym\"\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_HOSTS=[\"algo-1-xd9ym\"]\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_HPS={}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-xd9ym\",\"hosts\":[\"algo-1-xd9ym\"]}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_CURRENT_HOST=algo-1-xd9ym\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-118104210923/sagemaker-pytorch-2019-09-28-01-32-35-616/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-xd9ym\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-xd9ym\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-09-28-01-32-35-616\",\"log_level\":20,\"master_hostname\":\"algo-1-xd9ym\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-118104210923/sagemaker-pytorch-2019-09-28-01-32-35-616/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-xd9ym\",\"hosts\":[\"algo-1-xd9ym\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m PYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m /usr/bin/python -m train\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m ['/opt/ml/input/data/training/textclass.json']\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Number of data frames length:  1\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Concat data\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m                                            sentence1  ...  travel\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0  Conceptually cream skimming has two basic dime...  ...       0\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 1  yeah i tell you what though if you go price so...  ...       0\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [2 rows x 6 columns]\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Length of data  130900\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Frame columns Index(['sentence1', 'fiction', 'government', 'slate', 'telephone', 'travel'], dtype='object')\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Number of unique labels: 5\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Number of training examples: 79\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Number of testing examples: 52\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Loaded model 'en_pytt_xlnetbasecased_lg'\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Adding fiction\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Adding government\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Adding slate\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Adding telephone\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Adding travel\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Labels: ('fiction', 'government', 'slate', 'telephone', 'travel')\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Using 79 training docs, 52 evaluation\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Training the model...\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m LOSS \t  P  \t  R  \t  F  \n",
      "\u001b[38;5;3m⚠ Losses: [0.208] Precision: [0.000] Recall: [0.000] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.000]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.376] Precision: [0.000] Recall: [0.000] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.000]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.520] Precision: [0.000] Recall: [0.000] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.000]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.672] Precision: [0.000] Recall: [0.000] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.000]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.791] Precision: [0.400] Recall: [0.038] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.070]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.951] Precision: [0.154] Recall: [0.038] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.062]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.07017543857186827  best_step : 15  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 1\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [5] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ Best scoring checkpoints\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Epoch   Step   Score \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m --   ----   ------\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    15     7.02  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    18     6.15  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    12     0.00  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    9      0.00  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    6      0.00  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    3      0.00  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m yeah it had a it had a had a has a bust of somebody on there but uh no sort of identifying marks or anything {'fiction': 0.2572857141494751, 'government': 0.06661919504404068, 'slate': 0.12220153957605362, 'telephone': 0.3756554126739502, 'travel': 0.178238183259964}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.034] Precision: [0.333] Recall: [0.019] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.036]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.157] Precision: [0.600] Recall: [0.058] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.105]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.270] Precision: [0.769] Recall: [0.192] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.308]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.335] Precision: [0.842] Recall: [0.308] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.451]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.432] Precision: [0.885] Recall: [0.442] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.590]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.506] Precision: [0.848] Recall: [0.538] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.659]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.548] Precision: [0.825] Recall: [0.635] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.717]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.7173913041918715  best_step : 21  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 0\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [2] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ Best scoring checkpoints\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Epoch   Step   Score \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m --   ----   ------\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    21     71.74 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    18     65.88 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    15     58.97 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    12     45.07 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    9      30.77 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    6      10.53 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    15     7.02  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    18     6.15  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    3      3.64  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    12     0.00  \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m yeah it had a it had a had a has a bust of somebody on there but uh no sort of identifying marks or anything {'fiction': 4.1572457121219486e-05, 'government': 3.214508615201339e-05, 'slate': 1.4818551790085621e-05, 'telephone': 0.9999076128005981, 'travel': 3.7620623061229708e-06}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.015] Precision: [0.739] Recall: [0.654] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.694]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.113] Precision: [0.646] Recall: [0.596] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.620]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.156] Precision: [0.640] Recall: [0.615] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.627]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.182] Precision: [0.681] Recall: [0.615] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.646]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.227] Precision: [0.792] Recall: [0.731] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.760]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.228] Precision: [0.766] Recall: [0.692] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.727]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.255] Precision: [0.653] Recall: [0.615] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.634]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.759999999848  best_step : 24  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 2\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [8] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ Best scoring checkpoints\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Epoch   Step   Score \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m --   ----   ------\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    24     76.00 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    27     72.73 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    21     71.74 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    12     69.39 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    18     65.88 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    21     64.65 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    30     63.37 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    18     62.75 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    15     62.00 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    15     58.97 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m yeah it had a it had a had a has a bust of somebody on there but uh no sort of identifying marks or anything {'fiction': 6.478121122199809e-06, 'government': 4.0847939430932456e-07, 'slate': 1.2454590603283577e-07, 'telephone': 0.9999738931655884, 'travel': 1.9073206203756854e-05}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.002] Precision: [0.615] Recall: [0.615] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.615]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.012] Precision: [0.627] Recall: [0.615] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.621]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.013] Precision: [0.653] Recall: [0.615] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.634]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.027] Precision: [0.735] Recall: [0.692] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.713]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.044] Precision: [0.820] Recall: [0.788] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.804]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.045] Precision: [0.843] Recall: [0.827] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.835]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.109] Precision: [0.857] Recall: [0.808] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.832]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.834951456148553  best_step : 30  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 1\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [5] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ Best scoring checkpoints\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Epoch   Step   Score \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m --   ----   ------\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    30     83.50 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    33     83.17 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    27     80.39 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    24     76.00 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    27     72.73 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    21     71.74 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    24     71.29 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    12     69.39 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    18     65.88 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 0    21     64.65 \n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m yeah it had a it had a had a has a bust of somebody on there but uh no sort of identifying marks or anything {'fiction': 1.0254591131797497e-07, 'government': 3.564005908174295e-07, 'slate': 2.2096548590866405e-08, 'telephone': 0.9999898672103882, 'travel': 9.639574273023754e-06}\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.000] Precision: [0.860] Recall: [0.827] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.843]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.000] Precision: [0.840] Recall: [0.808] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.824]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.000] Precision: [0.827] Recall: [0.827] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.827]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.000] Precision: [0.827] Recall: [0.827] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.827]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.000] Precision: [0.827] Recall: [0.827] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.827]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.012] Precision: [0.827] Recall: [0.827] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.827]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.012] Precision: [0.808] Recall: [0.808] F1-Score:\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m [0.808]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.8431372547366397  best_step : 21  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 6\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [20] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m Finished training. Model saved!\n",
      "\u001b[36malgo-1-xd9ym_1  |\u001b[0m 2019-09-28 01:43:32,848 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmprnc594mq_algo-1-xd9ym_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': 'file://textclass.json'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('textclass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[0],axis=1).to_csv('textclass.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df[df.columns.difference(['sentence1'])].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('textclass.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_json('textclass.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.fiction.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: pandas==0.25.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.25.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: wasabi==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.2.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: gputil==1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.21.3)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: tqdm==4.36.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.36.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: joblib==0.13.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: spacy-pytorch-transformers[cuda100]==0.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.4.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: en_pytt_xlnetbasecased_lg from https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz#egg=en_pytt_xlnetbasecased_lg in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2.1.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (2019.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (1.16.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (2.8.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: spacy<2.2.0,>=2.1.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.1.8)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: ftfy<6.0.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (5.6)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.6)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.1.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.7)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: pytorch-transformers<1.3.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.2.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: torchcontrib<0.1.0,>=0.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: thinc-gpu-ops<0.1.0,>=0.0.1; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: cupy-cuda100>=5.0.0b4; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0.0b4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.1->-r requirements.txt (line 1)) (1.12.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0.8)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.9.6)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.0.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.0.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.22.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.2.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.0.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.1.7)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2019.8.19)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.1.83)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.34)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.9.209)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.8)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.25.3)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2019.6.16)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (3.0.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: botocore<1.13.0,>=1.12.209 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.12.209)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.2.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.9.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.209->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.15.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Building wheels for collected packages: train\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m   Running setup.py bdist_wheel for train ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m \u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-9hfzra3d/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Successfully built train\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Installing collected packages: train\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m   Found existing installation: train 1.0.0\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m     Uninstalling train-1.0.0:\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m       Successfully uninstalled train-1.0.0\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Successfully installed train-1.0.0\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m \u001b[33mYou are using pip version 18.1, however version 19.2.3 is available.\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 596, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 657, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 601, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmpzz1axc9v/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [model_fn] pipelines [('sentencizer', <spacy.pipeline.pipes.Sentencizer object at 0x7f39de37abe0>), ('pytt_wordpiecer', <spacy_pytorch_transformers.pipeline.wordpiecer.PyTT_WordPiecer object at 0x7f39de37ac18>), ('pytt_tok2vec', <spacy_pytorch_transformers.pipeline.tok2vec.PyTT_TokenVectorEncoder object at 0x7f39e0526eb8>), ('pytt_textcat', <spacy_pytorch_transformers.pipeline.textcat.PyTT_TextCategorizer object at 0x7f39dd671c88>)]\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [model_fn]  <spacy_pytorch_transformers.language.PyTT_Language object at 0x7f39f939d668>\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m 172.18.0.1 - - [28/Sep/2019:01:48:00 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n",
      "!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "predictor.content_type = CONTENT_TYPE_JSON\n",
    "predictor.accept = CONTENT_TYPE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('textclass.json') as json_file:\n",
    "    q = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: pandas==0.25.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.25.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: wasabi==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.2.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: gputil==1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.21.3)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: tqdm==4.36.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.36.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: joblib==0.13.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: spacy-pytorch-transformers[cuda100]==0.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.4.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: en_pytt_xlnetbasecased_lg from https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz#egg=en_pytt_xlnetbasecased_lg in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2.1.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (2019.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (1.16.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (2.8.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.6)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: ftfy<6.0.0,>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (5.6)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.7)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: spacy<2.2.0,>=2.1.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.1.8)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.1.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: torchcontrib<0.1.0,>=0.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: pytorch-transformers<1.3.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.2.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: cupy-cuda100>=5.0.0b4; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0.0b4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: thinc-gpu-ops<0.1.0,>=0.0.1; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.1->-r requirements.txt (line 1)) (1.12.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0.0,>=5.0.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.1.7)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.0.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.9.6)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0.8)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.2.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.0.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.0.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.22.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.9.209)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.34)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2019.8.19)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.1.83)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.25.3)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (3.0.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.8)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2019.6.16)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.2.1)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.9.4)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: botocore<1.13.0,>=1.12.209 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.12.209)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.209->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.15.2)\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Building wheels for collected packages: train\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m   Running setup.py bdist_wheel for train ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m \u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-x7d2d6ug/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Successfully built train\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Installing collected packages: train\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m   Found existing installation: train 1.0.0\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m     Uninstalling train-1.0.0:\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m       Successfully uninstalled train-1.0.0\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m Successfully installed train-1.0.0\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m \u001b[33mYou are using pip version 18.1, however version 19.2.3 is available.\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [model_fn] pipelines [('sentencizer', <spacy.pipeline.pipes.Sentencizer object at 0x7f39de379cc0>), ('pytt_wordpiecer', <spacy_pytorch_transformers.pipeline.wordpiecer.PyTT_WordPiecer object at 0x7f39de379cf8>), ('pytt_tok2vec', <spacy_pytorch_transformers.pipeline.tok2vec.PyTT_TokenVectorEncoder object at 0x7f39e0526198>), ('pytt_textcat', <spacy_pytorch_transformers.pipeline.textcat.PyTT_TextCategorizer object at 0x7f39dd671d68>)]\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [model_fn]  <spacy_pytorch_transformers.language.PyTT_Language object at 0x7f39f939a780>\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [input_fn] - Input type: <class 'str'>\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [predict_fn] Input Type:  <class 'list'>\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [predict_fn] Input:  [{'sentence1': 'Conceptually cream skimming has two basic dimensions - product and geography.', 'fiction': 0, 'government': 1, 'slate': 0, 'telephone': 0, 'travel': 0}]\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [predict_fn] cats:  {'fiction': 0.00036576588172465563, 'government': 0.42736703157424927, 'slate': 0.3365786075592041, 'telephone': 7.278428529389203e-05, 'travel': 0.23561587929725647}\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [predict_fn] Model:  <spacy_pytorch_transformers.language.PyTT_Language object at 0x7f39f939a780>\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [output_fn] Prediction:  [{'fiction': 0.00036576588172465563, 'government': 0.42736703157424927, 'slate': 0.3365786075592041, 'telephone': 7.278428529389203e-05, 'travel': 0.23561587929725647}]\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m [output_fn] Accept:  application/json\n",
      "\u001b[36malgo-1-doh2w_1  |\u001b[0m 172.18.0.1 - - [28/Sep/2019:01:48:23 +0000] \"POST /invocations HTTP/1.1\" 200 168 \"-\" \"-\"\n"
     ]
    }
   ],
   "source": [
    "a = predictor.predict([q[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q[0]['sentence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fiction': 0.00036576588172465563,\n",
       "  'government': 0.42736703157424927,\n",
       "  'slate': 0.3365786075592041,\n",
       "  'telephone': 7.278428529389203e-05,\n",
       "  'travel': 0.23561587929725647}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
