{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.1.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='local',\n",
    "                    source_dir='.'\n",
    "#                     image_name='118104210923.dkr.ecr.us-east-1.amazonaws.com/spacy-pytorch-transformers:1.0.0-gpu-py3'\n",
    "#                     hyperparameters={\n",
    "#                         'epochs': 6,\n",
    "#                         'backend': 'gloo'\n",
    "#                     })\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmps9sa8y1n_algo-1-2vhi3_1 ... \n",
      "\u001b[1BAttaching to tmps9sa8y1n_algo-1-2vhi3_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:21:45,831 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:21:45,834 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:21:45,848 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:21:45,849 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:21:46,782 sagemaker-containers INFO     Module train does not provide a setup.py. \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:21:46,782 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:21:46,782 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:21:46,782 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m /usr/bin/python -m pip install . -r requirements.txt\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting pandas==0.25.1 (from -r requirements.txt (line 1))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.5MB 4.3MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: wasabi==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.2.2)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting gputil==1.4.0 (from -r requirements.txt (line 3))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting scikit-learn>=0.20.0 (from -r requirements.txt (line 4))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.7MB 6.8MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hCollecting tqdm==4.36.1 (from -r requirements.txt (line 5))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 24.0MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hCollecting joblib==0.13.2 (from -r requirements.txt (line 6))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K    100% |████████████████████████████████| 286kB 40.0MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hCollecting spacy-pytorch-transformers[cuda100]==0.4.0 (from -r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/46/3271586944ee5e0bd493df03b1ad189eb9ccdad1d2476aeb843b0d2f1b47/spacy_pytorch_transformers-0.4.0-py3-none-any.whl (62kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 33.8MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hCollecting en_pytt_xlnetbasecased_lg from https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz#egg=en_pytt_xlnetbasecased_lg (from -r requirements.txt (line 8))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz (433.9MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (2.8.0)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (1.16.4)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.1->-r requirements.txt (line 1)) (2019.2)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: spacy<2.2.0,>=2.1.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.1.8)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: srsly<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.0.7)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting pytorch-transformers<1.3.0,>=1.2.0 (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 38.9MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: dataclasses<0.7,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.6)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.1.0)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting torchcontrib<0.1.0,>=0.0.2 (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting ftfy<6.0.0,>=5.0.0 (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/2d9a5030eaf1bcd925dab392762b9709a7ad4bd486a90599d93cd79cb188/ftfy-5.6.tar.gz (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 27.5MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hCollecting cupy-cuda100>=5.0.0b4; extra == \"cuda100\" (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/40/e06241c414fbd1d9b0adb69a32f3759e40cfec92e76a07f27f186ab6a8e4/cupy_cuda100-7.0.0b4-cp36-cp36m-manylinux1_x86_64.whl (382.0MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hCollecting thinc-gpu-ops<0.1.0,>=0.0.1; extra == \"cuda100\" (from spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/ad/11ab80a24bcedd7dd0cfabaedba2ceaeca11f1aaeeff432a3d2e63ca7d02/thinc_gpu_ops-0.0.4.tar.gz (483kB)\n",
      "\u001b[K    100% |████████████████████████████████| 491kB 35.9MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.1->-r requirements.txt (line 1)) (1.12.0)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.9.6)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.0.1)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.0.2)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.22.0)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0.8)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.0.2)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.2.4)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting sentencepiece (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 24.1MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.9.209)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting regex (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
      "\u001b[K    100% |████████████████████████████████| 655kB 32.5MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hCollecting sacremoses (from pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/04/b92425ca552116afdb7698fa3f00ca1c975cfd86a847cf132fd813c5d901/sacremoses-0.0.34.tar.gz (859kB)\n",
      "\u001b[K    100% |████████████████████████████████| 860kB 25.4MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25hCollecting wcwidth (from ftfy<6.0.0,>=5.0.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Collecting fastrlock>=0.3 (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/b5/93/a7efbd39eac46c137500b37570c31dedc2d31a8ff4949fcb90bda5bc5f16/fastrlock-0.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2.8)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (2019.6.16)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (3.0.4)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.2.0,>=2.1.7->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.25.3)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.9.4)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.2.1)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: botocore<1.13.0,>=1.12.209 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (1.12.209)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (7.0)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.209->boto3->pytorch-transformers<1.3.0,>=1.2.0->spacy-pytorch-transformers[cuda100]==0.4.0->-r requirements.txt (line 7)) (0.15.2)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Building wheels for collected packages: gputil, en-pytt-xlnetbasecased-lg, train, torchcontrib, ftfy, thinc-gpu-ops, regex, sacremoses\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Running setup.py bdist_wheel for gputil ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Running setup.py bdist_wheel for en-pytt-xlnetbasecased-lg ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/30/9b/00/b570788126042185cd1f038f136e29f3a93a8dc824a35f6582\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Running setup.py bdist_wheel for train ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-by10h_rg/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Running setup.py bdist_wheel for torchcontrib ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Running setup.py bdist_wheel for ftfy ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/43/34/ce/cbb38d71543c408de56f3c5e26ce8ba495a0fa5a28eaaf1046\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Running setup.py bdist_wheel for thinc-gpu-ops ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/eb/ba/a3/9af9f326ed0d75a4540378af64a05a0e42be39d9b8513f3aea\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Running setup.py bdist_wheel for regex ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Running setup.py bdist_wheel for sacremoses ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[?25h  Stored in directory: /root/.cache/pip/wheels/07/b9/5b/8bd674c23e962fbff34420a9fa7a2c374d591ecadd5bc37684\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Successfully built gputil en-pytt-xlnetbasecased-lg train torchcontrib ftfy thinc-gpu-ops regex sacremoses\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Installing collected packages: pandas, gputil, joblib, scikit-learn, tqdm, sentencepiece, regex, sacremoses, pytorch-transformers, torchcontrib, wcwidth, ftfy, fastrlock, cupy-cuda100, thinc-gpu-ops, spacy-pytorch-transformers, en-pytt-xlnetbasecased-lg, train\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Found existing installation: pandas 0.25.0\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     Uninstalling pandas-0.25.0:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m       Successfully uninstalled pandas-0.25.0\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m   Found existing installation: tqdm 4.33.0\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     Uninstalling tqdm-4.33.0:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m       Successfully uninstalled tqdm-4.33.0\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Successfully installed cupy-cuda100-7.0.0b4 en-pytt-xlnetbasecased-lg-2.1.1 fastrlock-0.4 ftfy-5.6 gputil-1.4.0 joblib-0.13.2 pandas-0.25.1 pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.34 scikit-learn-0.21.3 sentencepiece-0.1.83 spacy-pytorch-transformers-0.4.0 thinc-gpu-ops-0.0.4 torchcontrib-0.0.2 tqdm-4.36.1 train-1.0.0 wcwidth-0.1.7\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[33mYou are using pip version 18.1, however version 19.2.3 is available.\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:23:27,774 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:23:27,787 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"current_host\": \"algo-1-2vhi3\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m         \"algo-1-2vhi3\"\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"job_name\": \"sagemaker-pytorch-2019-09-27-18-21-35-881\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"master_hostname\": \"algo-1-2vhi3\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-118104210923/sagemaker-pytorch-2019-09-27-18-21-35-881/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m         \"current_host\": \"algo-1-2vhi3\",\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m             \"algo-1-2vhi3\"\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_HOSTS=[\"algo-1-2vhi3\"]\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_HPS={}\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-2vhi3\",\"hosts\":[\"algo-1-2vhi3\"]}\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_CURRENT_HOST=algo-1-2vhi3\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-118104210923/sagemaker-pytorch-2019-09-27-18-21-35-881/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-2vhi3\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-2vhi3\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-09-27-18-21-35-881\",\"log_level\":20,\"master_hostname\":\"algo-1-2vhi3\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-118104210923/sagemaker-pytorch-2019-09-27-18-21-35-881/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-2vhi3\",\"hosts\":[\"algo-1-2vhi3\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m PYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m /usr/bin/python -m train\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m ['/opt/ml/input/data/training/textclass.json']\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Number of data frames length:  1\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Concat data\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m                                            sentence1  ...  travel\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0  Conceptually cream skimming has two basic dime...  ...       0\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 1  yeah i tell you what though if you go price so...  ...       0\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [2 rows x 6 columns]\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Length of data  130900\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Frame columns Index(['sentence1', 'fiction', 'government', 'slate', 'telephone', 'travel'], dtype='object')\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Number of unique labels: 5\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Number of training examples: 79\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Number of testing examples: 52\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Loaded model 'en_pytt_xlnetbasecased_lg'\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Adding fiction\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Adding government\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Adding slate\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Adding telephone\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Adding travel\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Labels: ('fiction', 'government', 'slate', 'telephone', 'travel')\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Using 79 training docs, 52 evaluation\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Training the model...\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m LOSS \t  P  \t  R  \t  F  \n",
      "\u001b[38;5;3m⚠ Losses: [0.209] Precision: [0.000] Recall: [0.000] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.000]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.370] Precision: [0.000] Recall: [0.000] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.000]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.492] Precision: [0.000] Recall: [0.000] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.000]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.637] Precision: [1.000] Recall: [0.058] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.109]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.757] Precision: [1.000] Recall: [0.096] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.175]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.931] Precision: [0.312] Recall: [0.096] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.147]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.1754385964296707  best_step : 15  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 1\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [5] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ Best scoring checkpoints\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Epoch   Step   Score \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m --   ----   ------\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    15     17.54 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    18     14.71 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    12     10.91 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    9      0.00  \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    6      0.00  \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    3      0.00  \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m yeah it had a it had a had a has a bust of somebody on there but uh no sort of identifying marks or anything {'fiction': 0.28116077184677124, 'government': 0.02279418148100376, 'slate': 0.20603740215301514, 'telephone': 0.3474615812301636, 'travel': 0.14254601299762726}\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.052] Precision: [0.400] Recall: [0.077] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.129]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.146] Precision: [0.800] Recall: [0.077] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.140]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.244] Precision: [0.654] Recall: [0.327] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.436]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.323] Precision: [0.667] Recall: [0.423] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.518]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.391] Precision: [0.750] Recall: [0.462] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.571]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.494] Precision: [0.711] Recall: [0.519] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.600]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.539] Precision: [0.763] Recall: [0.558] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.644]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.6444444443012345  best_step : 21  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 0\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [2] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ Best scoring checkpoints\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Epoch   Step   Score \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m --   ----   ------\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    21     64.44 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    18     60.00 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    15     57.14 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    12     51.76 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    9      43.59 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    15     17.54 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    18     14.71 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    6      14.04 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    3      12.90 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    12     10.91 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m yeah it had a it had a had a has a bust of somebody on there but uh no sort of identifying marks or anything {'fiction': 9.163606591755524e-05, 'government': 4.460730451683048e-06, 'slate': 9.745091119839344e-06, 'telephone': 0.9998922348022461, 'travel': 1.9169576717104064e-06}\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.013] Precision: [0.766] Recall: [0.692] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.727]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.079] Precision: [0.816] Recall: [0.769] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.792]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.162] Precision: [0.830] Recall: [0.750] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.788]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.162] Precision: [0.830] Recall: [0.750] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.788]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.177] Precision: [0.824] Recall: [0.808] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.816]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.182] Precision: [0.760] Recall: [0.731] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.745]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.249] Precision: [0.712] Recall: [0.712] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.712]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.8155339804241682  best_step : 24  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 2\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [8] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ Best scoring checkpoints\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Epoch   Step   Score \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m --   ----   ------\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    24     81.55 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    15     79.21 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    21     78.79 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    18     78.79 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    27     74.51 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    12     72.73 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    30     71.15 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    21     64.44 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    18     60.00 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 0    15     57.14 \n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m yeah it had a it had a had a has a bust of somebody on there but uh no sort of identifying marks or anything {'fiction': 2.551919124016422e-06, 'government': 7.687312404414115e-07, 'slate': 3.473229071460082e-06, 'telephone': 0.9999915361404419, 'travel': 1.6916820868573268e-06}\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.001] Precision: [0.706] Recall: [0.692] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.699]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.001] Precision: [0.692] Recall: [0.692] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.692]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.001] Precision: [0.750] Recall: [0.750] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.750]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.014] Precision: [0.804] Recall: [0.788] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.796]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.033] Precision: [0.804] Recall: [0.788] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.796]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.046] Precision: [0.804] Recall: [0.788] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.796]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;3m⚠ Losses: [0.046] Precision: [0.837] Recall: [0.788] F1-Score:\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m [0.812]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;2m✔ === Epoch 1 ===\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ best score: 0.8155339804241682  best_step : 24  best epoch : 0\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;4mℹ break clause: 3\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m \u001b[38;5;2m✔ (Step - Best step: [11] Eval Every: [3] Patience: [3]\u001b[0m\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m Finished training. Model saved!\n",
      "\u001b[36malgo-1-2vhi3_1  |\u001b[0m 2019-09-27 18:30:36,076 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmps9sa8y1n_algo-1-2vhi3_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': 'file://textclass.json'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('textclass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[0],axis=1).to_csv('textclass.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fiction', 'government', 'slate', 'telephone', 'travel']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[df.columns.difference(['sentence1'])].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('textclass.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_json('textclass.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.fiction.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpf4try1wj_algo-1-emsyv_1\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m 2019/09/27 18:41:40 [crit] 20#20: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m 172.18.0.1 - - [27/Sep/2019:18:41:40 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m Collecting pandas==0.25.1 (from -r requirements.txt (line 1))\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.5MB 4.4MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25hRequirement already satisfied: wasabi==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.2.2)\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m Collecting gputil==1.4.0 (from -r requirements.txt (line 3))\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m   Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m Collecting scikit-learn>=0.20.0 (from -r requirements.txt (line 4))\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.7MB 6.8MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25hCollecting tqdm==4.36.1 (from -r requirements.txt (line 5))\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 27.2MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25hCollecting joblib==0.13.2 (from -r requirements.txt (line 6))\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K    100% |████████████████████████████████| 286kB 39.4MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25hCollecting spacy-pytorch-transformers[cuda100]==0.4.0 (from -r requirements.txt (line 7))\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/46/3271586944ee5e0bd493df03b1ad189eb9ccdad1d2476aeb843b0d2f1b47/spacy_pytorch_transformers-0.4.0-py3-none-any.whl (62kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 35.4MB/s ta 0:00:01\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25hCollecting en_pytt_xlnetbasecased_lg from https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz#egg=en_pytt_xlnetbasecased_lg (from -r requirements.txt (line 8))\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_pytt_xlnetbasecased_lg-2.1.1/en_pytt_xlnetbasecased_lg-2.1.1.tar.gz (433.9MB)\n",
      "\u001b[K    20% |██████▊                         | 90.7MB 53.0MB/s eta 0:00:072019/09/27 18:41:45 [crit] 20#20: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m 172.18.0.1 - - [27/Sep/2019:18:41:45 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[K    40% |█████████████                   | 176.6MB 58.9MB/s eta 0:00:05\u001b[31mCould not install packages due to an EnvironmentError: [Errno 28] No space left on device\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[0m\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m \u001b[33mYou are using pip version 18.1, however version 19.2.3 is available.\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m   File \"/usr/local/bin/serve\", line 11, in <module>\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m     load_entry_point('sagemaker-containers==2.5.4', 'console_scripts', 'serve')()\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/cli/serve.py\", line 17, in main\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m     server.start(env.ServingEnv().framework_module)\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_server.py\", line 79, in start\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m     _modules.import_module(env.module_dir, env.module_name)\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_modules.py\", line 244, in import_module\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m     install(_env.code_dir)\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_modules.py\", line 110, in install\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m     _process.check_error(shlex.split(cmd), _errors.InstallModuleError, cwd=path, capture_error=capture_error)\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_process.py\", line 48, in check_error\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m     raise error_class(return_code=return_code, cmd=' '.join(cmd), output=stderr)\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m sagemaker_containers._errors.InstallModuleError: InstallModuleError:\n",
      "\u001b[36malgo-1-emsyv_1  |\u001b[0m Command \"/usr/bin/python -m pip install . -r requirements.txt\"\n",
      "\u001b[36mtmpf4try1wj_algo-1-emsyv_1 exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 596, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 657, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 601, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmpf4try1wj/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-77f9842ea160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_serializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_deserializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONTENT_TYPE_CSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONTENT_TYPE_JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_serializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_deserializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONTENT_TYPE_JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mtmp2876_ghs_algo-1-91sy2_1 exited with code 137\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 596, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 657, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 137\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 601, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmp2876_ghs/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "predictor.content_type = CONTENT_TYPE_JSON\n",
    "predictor.accept = CONTENT_TYPE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
